{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9862752,"sourceType":"datasetVersion","datasetId":6053377},{"sourceId":9946093,"sourceType":"datasetVersion","datasetId":6115970}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:53:05.118832Z","iopub.execute_input":"2024-11-24T00:53:05.119150Z","iopub.status.idle":"2024-11-24T00:53:05.442266Z","shell.execute_reply.started":"2024-11-24T00:53:05.119122Z","shell.execute_reply":"2024-11-24T00:53:05.441543Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Chargement des données ","metadata":{}},{"cell_type":"code","source":"X_train = pd.read_csv(\"/kaggle/input/cfm-data/X_train_N1UvY30.csv\")\nY_train = pd.read_csv(\"/kaggle/input/cfm-data/y_train_or6m3Ta.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:53:06.640057Z","iopub.execute_input":"2024-11-24T00:53:06.640885Z","iopub.status.idle":"2024-11-24T00:53:32.263177Z","shell.execute_reply.started":"2024-11-24T00:53:06.640852Z","shell.execute_reply":"2024-11-24T00:53:32.262410Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"X_test = pd.read_csv(\"/kaggle/input/x-test/X_test_m4HAPAP.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:53:32.264877Z","iopub.execute_input":"2024-11-24T00:53:32.265521Z","iopub.status.idle":"2024-11-24T00:53:45.169984Z","shell.execute_reply.started":"2024-11-24T00:53:32.265479Z","shell.execute_reply":"2024-11-24T00:53:45.168853Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"X_train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:37:16.267301Z","iopub.execute_input":"2024-11-19T20:37:16.268162Z","iopub.status.idle":"2024-11-19T20:37:16.276479Z","shell.execute_reply.started":"2024-11-19T20:37:16.268118Z","shell.execute_reply":"2024-11-19T20:37:16.275256Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Index(['obs_id', 'venue', 'order_id', 'action', 'side', 'price', 'bid', 'ask',\n       'bid_size', 'ask_size', 'trade', 'flux'],\n      dtype='object')"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"**Vérifier s'il existe des valeurs NA**","metadata":{}},{"cell_type":"code","source":"X_train.isnull().any()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:47:06.991391Z","iopub.execute_input":"2024-11-23T20:47:06.993559Z","iopub.status.idle":"2024-11-23T20:47:08.640243Z","shell.execute_reply.started":"2024-11-23T20:47:06.993461Z","shell.execute_reply":"2024-11-23T20:47:08.639058Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"obs_id      False\nvenue       False\norder_id    False\naction      False\nside        False\nprice       False\nbid         False\nask         False\nbid_size    False\nask_size    False\ntrade       False\nflux        False\ndtype: bool"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"X_test.isnull().any()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:54:02.093190Z","iopub.execute_input":"2024-11-23T20:54:02.094718Z","iopub.status.idle":"2024-11-23T20:54:02.893097Z","shell.execute_reply.started":"2024-11-23T20:54:02.094635Z","shell.execute_reply":"2024-11-23T20:54:02.891802Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"obs_id      False\nvenue       False\norder_id    False\naction      False\nside        False\nprice       False\nbid         False\nask         False\nbid_size    False\nask_size    False\ntrade       False\nflux        False\ndtype: bool"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"**type des données**","metadata":{}},{"cell_type":"code","source":"X_train.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:54:10.662922Z","iopub.execute_input":"2024-11-23T20:54:10.663461Z","iopub.status.idle":"2024-11-23T20:54:10.674534Z","shell.execute_reply.started":"2024-11-23T20:54:10.663406Z","shell.execute_reply":"2024-11-23T20:54:10.673021Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"obs_id        int64\nvenue         int64\norder_id      int64\naction       object\nside         object\nprice       float64\nbid         float64\nask         float64\nbid_size      int64\nask_size      int64\ntrade          bool\nflux          int64\ndtype: object"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Première approche : extraction des caractéristiques des observations","metadata":{"execution":{"iopub.status.busy":"2024-11-23T20:54:55.055558Z","iopub.execute_input":"2024-11-23T20:54:55.056056Z","iopub.status.idle":"2024-11-23T20:54:55.061331Z","shell.execute_reply.started":"2024-11-23T20:54:55.056016Z","shell.execute_reply":"2024-11-23T20:54:55.060242Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.stattools import acf\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # Ignore runtime warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\nclass FeatureExtractor:\n    def __init__(self, df):\n        self.scaler = StandardScaler()  # Optional: Use scaling for numerical stability\n        \n        \n    def transform(self, df):\n        df['spread'] = df['ask'] - df['bid']\n        \n        # Aggregate features\n        aggregated_df = df.groupby('obs_id').agg(\n            # Market behavior features\n            price_mean=('price', 'mean'),\n            price_std=('price', 'std'),\n            price_min=('price', 'min'),\n            price_max=('price', 'max'),\n            price_range=('price', lambda x: x.max() - x.min()),\n            \n            \n            bid_mean=('bid', 'mean'),\n            bid_std=('bid', 'std'),\n            bid_min=('bid', 'min'),\n            bid_max=('bid', 'max'),\n            bid_range=('bid', lambda x: x.max() - x.min()),\n            \n            \n            ask_mean=('ask', 'mean'),\n            ask_std=('ask', 'std'),\n            ask_min=('ask', 'min'),\n            ask_max=('ask', 'max'),\n            ask_range=('ask', lambda x: x.max() - x.min()),\n            \n            \n            bid_size_mean=('bid_size', 'mean'),\n            ask_size_mean=('ask_size', 'mean'),\n            flux_mean=('flux', 'mean'),\n            flux_std=('flux', 'std'),\n            flux_min=('flux', 'min'),\n            flux_max=('flux', 'max'),\n            flux_range=('flux', lambda x: x.max() - x.min()),\n            \n            \n            # Spread features\n            spread_mean=('spread', 'mean'),\n            spread_std=('spread', 'std'),\n            \n            # Exchange dynamics features\n            venue_unique=('venue', lambda x: x.nunique()),\n            \n            # Trade-related features\n            trade_rate=('trade', 'mean')\n        ).reset_index()\n\n        # Add venue-specific counts\n        venue_counts = df.groupby(['obs_id', 'venue']).size().unstack(fill_value=0)\n        for venue in venue_counts.columns:\n            aggregated_df[f'venue_{venue}_count'] = venue_counts[venue].values\n        \n        # Add action type features\n        action_counts = df.groupby(['obs_id', 'action']).size().unstack(fill_value=0).div(\n            df.groupby('obs_id')['action'].count(), axis=0\n        )\n        for action in ['A', 'D', 'U']:\n            if action in action_counts.columns:\n                aggregated_df[f'action_{action}_freq'] = action_counts[action].values\n            else:\n                aggregated_df[f'action_{action}_freq'] = 0.0\n        \n        # Add side features\n        side_counts = df.groupby(['obs_id', 'side']).size().unstack(fill_value=0).div(\n            df.groupby('obs_id')['side'].count(), axis=0\n        )\n        for side in ['A', 'B']:\n            if side in side_counts.columns:\n                aggregated_df[f'side_{side}_freq'] = side_counts[side].values\n            else:\n                aggregated_df[f'side_{side}_freq'] = 0.0\n        \n        # Add flux autocorrelation\n        autocorrs = df.groupby('obs_id')['flux'].apply(\n            lambda x: acf(x, nlags=1, fft=True)[1] if len(x) > 1 else np.nan\n        )\n        aggregated_df['flux_autocorr'] = aggregated_df['obs_id'].map(autocorrs)\n        \n        return aggregated_df.drop(columns=[\"obs_id\"])\n\n# Fit the extractor on the training data\nfeature_extractor = FeatureExtractor(X_train)\n\n# Apply the same feature extraction process to both training and test datasets\nfeatures_train = feature_extractor.transform(X_train)\n\nfeatures_test = feature_extractor.transform(X_test)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:20:30.419592Z","iopub.execute_input":"2024-11-23T22:20:30.420842Z","iopub.status.idle":"2024-11-23T22:22:43.012303Z","shell.execute_reply.started":"2024-11-23T22:20:30.420790Z","shell.execute_reply":"2024-11-23T22:22:43.011085Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Reorder the columns of features_test to match features_train\nfeatures_test = features_test[features_train.columns]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:22:51.283401Z","iopub.execute_input":"2024-11-23T22:22:51.283852Z","iopub.status.idle":"2024-11-23T22:22:51.296779Z","shell.execute_reply.started":"2024-11-23T22:22:51.283813Z","shell.execute_reply":"2024-11-23T22:22:51.295518Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"y = Y_train.drop(columns = [\"obs_id\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:23:46.186926Z","iopub.execute_input":"2024-11-23T22:23:46.187394Z","iopub.status.idle":"2024-11-23T22:23:46.197962Z","shell.execute_reply.started":"2024-11-23T22:23:46.187352Z","shell.execute_reply":"2024-11-23T22:23:46.196543Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df = features_train.copy()\ndf[\"target\"] = y.values\nsample_frac = 0.2  # Fraction of data to sample\n\n#Sampling\ndf_sample = df.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=sample_frac, random_state=42))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:46:26.732180Z","iopub.execute_input":"2024-11-23T22:46:26.733302Z","iopub.status.idle":"2024-11-23T22:46:27.143654Z","shell.execute_reply.started":"2024-11-23T22:46:26.733244Z","shell.execute_reply":"2024-11-23T22:46:27.142296Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2674186974.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sample = df.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=sample_frac, random_state=42))\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"**Echantillonnage pour optimiser les hyperparamètres**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\n\n\n# Split into train and test sets\nxtrain, xtest, ytrain, ytest = train_test_split(df_sample.drop(columns = [\"target\"]), df_sample[\"target\"],\n                                                stratify= df_sample[\"target\"],test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:49:21.704237Z","iopub.execute_input":"2024-11-23T22:49:21.704771Z","iopub.status.idle":"2024-11-23T22:49:21.740222Z","shell.execute_reply.started":"2024-11-23T22:49:21.704727Z","shell.execute_reply":"2024-11-23T22:49:21.739059Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\n\n# --- Grid Search for Random Forest ---\n\nprint(\"RF training : \")\n\nrf_model = RandomForestClassifier(random_state=42)\n\n# parameter grid for Random Forest\nparam_grid_rf = {\n    'n_estimators': [100, 200, 300, 400],  # Number of trees in the forest\n    'max_depth': [5, 10, 20, None],  # Depth of trees\n \n}\n\n# GridSearchCV with Random Forest\ngrid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=4, n_jobs=-1, verbose=2)\ngrid_search_rf.fit(xtrain, ytrain)\n\n# Best parameters and model from GridSearchCV\nbest_rf_model = grid_search_rf.best_estimator_\nprint(\"Best Random Forest Parameters:\", grid_search_rf.best_params_)\n\n# Predict on test set using the best Random Forest model\ny_pred_rf = best_rf_model.predict(xtest)\n\n# Evaluate the Random Forest model\nprint(\"Random Forest Accuracy:\", accuracy_score(ytest, y_pred_rf))\n\n# --- XGBoost Model with GridSearch ---\nxgb_model = xgb.XGBClassifier(random_state=42)\n\nprint(\"xgb training : \")\n# parameter grid for XGBoost\nparam_grid_xgb = {\n    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n    'learning_rate': [0.01, 0.05, 0.1],  # Step size shrinking to make the model robust\n    'gamma': [0, 0.1, 0.2],           # Regularization parameter (controls the complexity of the trees)\n}\n\n\n# GridSearchCV with XGBoost\ngrid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=4, n_jobs=-1, verbose=2)\ngrid_search_xgb.fit(xtrain, ytrain)\n\n# Best parameters and model from GridSearchCV\nbest_xgb_model = grid_search_xgb.best_estimator_\nprint(\"Best XGBoost Parameters:\", grid_search_xgb.best_params_)\n\n# Predict on test set using the best XGBoost model\ny_pred_xgb = best_xgb_model.predict(xtest)\n\n# Evaluate the XGBoost model\nprint(\"XGBoost Accuracy:\", accuracy_score(ytest, y_pred_xgb))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T22:51:32.458864Z","iopub.execute_input":"2024-11-23T22:51:32.459352Z","iopub.status.idle":"2024-11-23T23:31:34.254939Z","shell.execute_reply.started":"2024-11-23T22:51:32.459314Z","shell.execute_reply":"2024-11-23T23:31:34.252999Z"}},"outputs":[{"name":"stdout","text":"RF training : \nFitting 4 folds for each of 16 candidates, totalling 64 fits\n[CV] END ......................max_depth=5, n_estimators=100; total time=   5.0s\n[CV] END ......................max_depth=5, n_estimators=200; total time=   9.8s\n[CV] END ......................max_depth=5, n_estimators=300; total time=  15.2s\n[CV] END ......................max_depth=5, n_estimators=400; total time=  19.4s\n[CV] END .....................max_depth=10, n_estimators=100; total time=   9.7s\n[CV] END .....................max_depth=10, n_estimators=200; total time=  18.7s\n[CV] END .....................max_depth=10, n_estimators=300; total time=  29.2s\n[CV] END .....................max_depth=10, n_estimators=400; total time=  38.2s\n[CV] END .....................max_depth=20, n_estimators=100; total time=  16.6s\n[CV] END .....................max_depth=20, n_estimators=200; total time=  33.6s\n[CV] END .....................max_depth=20, n_estimators=300; total time=  49.5s\n[CV] END .....................max_depth=20, n_estimators=400; total time= 1.1min\n[CV] END ...................max_depth=None, n_estimators=100; total time=  17.3s\n[CV] END ...................max_depth=None, n_estimators=200; total time=  34.6s\n[CV] END ...................max_depth=None, n_estimators=300; total time=  52.3s\n[CV] END ...................max_depth=None, n_estimators=400; total time= 1.2min\n[CV] END ......................max_depth=5, n_estimators=100; total time=   4.8s\n[CV] END ......................max_depth=5, n_estimators=200; total time=   9.6s\n[CV] END ......................max_depth=5, n_estimators=300; total time=  15.2s\n[CV] END ......................max_depth=5, n_estimators=400; total time=  19.5s\n[CV] END .....................max_depth=10, n_estimators=100; total time=  10.1s\n[CV] END .....................max_depth=10, n_estimators=200; total time=  18.8s\n[CV] END .....................max_depth=10, n_estimators=300; total time=  28.5s\n[CV] END .....................max_depth=10, n_estimators=400; total time=  38.8s\n[CV] END .....................max_depth=20, n_estimators=100; total time=  17.4s\n[CV] END .....................max_depth=20, n_estimators=200; total time=  33.5s\n[CV] END .....................max_depth=20, n_estimators=300; total time=  50.2s\n[CV] END .....................max_depth=20, n_estimators=400; total time= 1.1min\n[CV] END ...................max_depth=None, n_estimators=100; total time=  17.0s\n[CV] END ...................max_depth=None, n_estimators=200; total time=  35.0s\n[CV] END ...................max_depth=None, n_estimators=300; total time=  52.4s\n[CV] END ...................max_depth=None, n_estimators=400; total time= 1.2min\n[CV] END ......................max_depth=5, n_estimators=100; total time=   4.9s\n[CV] END ......................max_depth=5, n_estimators=200; total time=   9.6s\n[CV] END ......................max_depth=5, n_estimators=300; total time=  14.6s\n[CV] END ......................max_depth=5, n_estimators=400; total time=  19.1s\n[CV] END .....................max_depth=10, n_estimators=100; total time=  10.5s\n[CV] END .....................max_depth=10, n_estimators=200; total time=  18.9s\n[CV] END .....................max_depth=10, n_estimators=300; total time=  29.0s\n[CV] END .....................max_depth=10, n_estimators=400; total time=  38.7s\n[CV] END .....................max_depth=20, n_estimators=100; total time=  17.3s\n[CV] END .....................max_depth=20, n_estimators=200; total time=  34.1s\n[CV] END .....................max_depth=20, n_estimators=300; total time=  50.7s\n[CV] END .....................max_depth=20, n_estimators=400; total time= 1.1min\n[CV] END ...................max_depth=None, n_estimators=100; total time=  16.8s\n[CV] END ...................max_depth=None, n_estimators=200; total time=  34.5s\n[CV] END ...................max_depth=None, n_estimators=300; total time=  52.2s\n[CV] END ...................max_depth=None, n_estimators=400; total time= 1.2min\nBest Random Forest Parameters: {'max_depth': 20, 'n_estimators': 400}\nRandom Forest Accuracy: 0.46921641791044777\nxgb training : \nFitting 4 folds for each of 27 candidates, totalling 108 fits\n[CV] END ......................max_depth=5, n_estimators=100; total time=   4.8s\n[CV] END ......................max_depth=5, n_estimators=200; total time=   9.7s\n[CV] END ......................max_depth=5, n_estimators=300; total time=  15.3s\n[CV] END ......................max_depth=5, n_estimators=400; total time=  19.6s\n[CV] END .....................max_depth=10, n_estimators=100; total time=   9.5s\n[CV] END .....................max_depth=10, n_estimators=200; total time=  18.9s\n[CV] END .....................max_depth=10, n_estimators=300; total time=  29.1s\n[CV] END .....................max_depth=10, n_estimators=400; total time=  37.9s\n[CV] END .....................max_depth=20, n_estimators=100; total time=  17.1s\n[CV] END .....................max_depth=20, n_estimators=200; total time=  33.3s\n[CV] END .....................max_depth=20, n_estimators=300; total time=  50.0s\n[CV] END .....................max_depth=20, n_estimators=400; total time= 1.1min\n[CV] END ...................max_depth=None, n_estimators=100; total time=  17.1s\n[CV] END ...................max_depth=None, n_estimators=200; total time=  34.9s\n[CV] END ...................max_depth=None, n_estimators=300; total time=  52.9s\n[CV] END ...................max_depth=None, n_estimators=400; total time= 1.2min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=100; total time=  38.2s\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=100; total time=  35.0s\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=100; total time=  32.5s\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=300; total time= 1.6min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=100; total time=  38.4s\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=100; total time=  35.0s\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=100; total time=  32.9s\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=300; total time= 1.5min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=100; total time=  37.2s\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=300; total time= 1.8min\nBest XGBoost Parameters: {'gamma': 0.1, 'learning_rate': 0.1, 'n_estimators': 300}\nXGBoost Accuracy: 0.49735696517412936\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"XGB_model = xgb.XGBClassifier(**{'gamma': 0.1, 'learning_rate': 0.1, 'n_estimators': 300})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:32:44.366246Z","iopub.execute_input":"2024-11-23T23:32:44.366789Z","iopub.status.idle":"2024-11-23T23:32:44.374850Z","shell.execute_reply.started":"2024-11-23T23:32:44.366743Z","shell.execute_reply":"2024-11-23T23:32:44.372913Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"RF_model = RandomForestClassifier(**{'max_depth': 20, 'n_estimators': 400})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:41:00.572869Z","iopub.execute_input":"2024-11-23T23:41:00.573373Z","iopub.status.idle":"2024-11-23T23:41:00.579445Z","shell.execute_reply.started":"2024-11-23T23:41:00.573334Z","shell.execute_reply":"2024-11-23T23:41:00.578093Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"RF_model.fit(features_train, y)\n\ny_pred_RF = RF_model.predict(features_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:41:21.853623Z","iopub.execute_input":"2024-11-23T23:41:21.854072Z","iopub.status.idle":"2024-11-23T23:48:38.662855Z","shell.execute_reply.started":"2024-11-23T23:41:21.854036Z","shell.execute_reply":"2024-11-23T23:48:38.661527Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"XGB_model.fit(features_train, y)\n\ny_pred = XGB_model.predict(features_test)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:33:47.600535Z","iopub.execute_input":"2024-11-23T23:33:47.600964Z","iopub.status.idle":"2024-11-23T23:36:08.110087Z","shell.execute_reply.started":"2024-11-23T23:33:47.600928Z","shell.execute_reply":"2024-11-23T23:36:08.109048Z"}},"outputs":[{"name":"stdout","text":"[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=100; total time=  35.3s\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=100; total time=  32.6s\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=300; total time= 1.3min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=100; total time=  37.7s\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=200; total time= 1.3min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=300; total time= 1.9min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=100; total time=  35.3s\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=100; total time=  33.2s\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=200; total time= 1.1min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=300; total time= 1.6min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=100; total time=  37.7s\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=100; total time=  34.7s\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=100; total time=  32.9s\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=300; total time= 1.5min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=100; total time=  37.4s\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=200; total time= 1.3min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=100; total time=  35.1s\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=100; total time=  32.3s\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=300; total time= 1.3min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=100; total time=  38.1s\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=200; total time= 1.3min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=300; total time= 1.9min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=100; total time=  35.2s\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=100; total time=  33.2s\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=300; total time= 1.6min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=100; total time=  38.2s\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=100; total time=  34.4s\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=100; total time=  33.1s\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=300; total time= 1.5min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=100; total time=  37.2s\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=100; total time=  35.1s\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=100; total time=  33.0s\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=300; total time= 1.3min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=100; total time=  37.7s\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=200; total time= 1.3min\n[CV] END ......gamma=0, learning_rate=0.01, n_estimators=300; total time= 1.9min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=100; total time=  35.0s\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ......gamma=0, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=100; total time=  32.7s\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .......gamma=0, learning_rate=0.1, n_estimators=300; total time= 1.6min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=100; total time=  38.0s\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=200; total time= 1.3min\n[CV] END ....gamma=0.1, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=100; total time=  35.2s\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.1, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=100; total time=  32.7s\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.1, learning_rate=0.1, n_estimators=300; total time= 1.5min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=100; total time=  37.8s\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=200; total time= 1.2min\n[CV] END ....gamma=0.2, learning_rate=0.01, n_estimators=300; total time= 1.8min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=100; total time=  35.2s\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=200; total time= 1.1min\n[CV] END ....gamma=0.2, learning_rate=0.05, n_estimators=300; total time= 1.6min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=100; total time=  32.7s\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=200; total time= 1.0min\n[CV] END .....gamma=0.2, learning_rate=0.1, n_estimators=300; total time= 1.3min\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"dfY_test = pd.DataFrame({\"obs_id\" : [k for k in range(81600)], \"eqt_code_cat\": y_pred})\ndfY_test.to_csv(\"predictions1.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:37:59.573894Z","iopub.execute_input":"2024-11-23T23:37:59.574340Z","iopub.status.idle":"2024-11-23T23:37:59.673686Z","shell.execute_reply.started":"2024-11-23T23:37:59.574304Z","shell.execute_reply":"2024-11-23T23:37:59.672482Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"dfY_test = pd.DataFrame({\"obs_id\" : [k for k in range(81600)], \"eqt_code_cat\": y_pred_RF})\ndfY_test.to_csv(\"predictions1RF.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:49:25.252615Z","iopub.execute_input":"2024-11-23T23:49:25.253059Z","iopub.status.idle":"2024-11-23T23:49:25.358312Z","shell.execute_reply.started":"2024-11-23T23:49:25.253021Z","shell.execute_reply":"2024-11-23T23:49:25.357296Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"## Deuxième approche : Mettre les valeurs des ordres en colonne","metadata":{}},{"cell_type":"code","source":"df = X_train.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:53:59.840951Z","iopub.execute_input":"2024-11-24T00:53:59.841279Z","iopub.status.idle":"2024-11-24T00:54:00.512877Z","shell.execute_reply.started":"2024-11-24T00:53:59.841252Z","shell.execute_reply":"2024-11-24T00:54:00.511925Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**On rajoute un identifiant pour chaque operation pour qu'on puisse utiliser la méthode pivot**","metadata":{}},{"cell_type":"code","source":"df[\"operation_id\"] = df.groupby(\"obs_id\").cumcount()\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:54:03.445008Z","iopub.execute_input":"2024-11-24T00:54:03.445300Z","iopub.status.idle":"2024-11-24T00:54:04.298375Z","shell.execute_reply.started":"2024-11-24T00:54:03.445273Z","shell.execute_reply":"2024-11-24T00:54:04.297487Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   obs_id  venue  order_id action side  price  bid   ask  bid_size  ask_size  \\\n0       0      4         0      A    A   0.30  0.0  0.01       100         1   \n1       0      4         1      A    B  -0.17  0.0  0.01       100         1   \n2       0      4         2      D    A   0.28  0.0  0.01       100         1   \n3       0      4         3      A    A   0.30  0.0  0.01       100         1   \n4       0      4         4      D    A   0.37  0.0  0.01       100         1   \n\n   trade  flux  operation_id  \n0  False   100             0  \n1  False   100             1  \n2  False  -100             2  \n3  False   100             3  \n4  False  -100             4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs_id</th>\n      <th>venue</th>\n      <th>order_id</th>\n      <th>action</th>\n      <th>side</th>\n      <th>price</th>\n      <th>bid</th>\n      <th>ask</th>\n      <th>bid_size</th>\n      <th>ask_size</th>\n      <th>trade</th>\n      <th>flux</th>\n      <th>operation_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>A</td>\n      <td>A</td>\n      <td>0.30</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>False</td>\n      <td>100</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>B</td>\n      <td>-0.17</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>False</td>\n      <td>100</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>D</td>\n      <td>A</td>\n      <td>0.28</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>False</td>\n      <td>-100</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>A</td>\n      <td>A</td>\n      <td>0.30</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>False</td>\n      <td>100</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>D</td>\n      <td>A</td>\n      <td>0.37</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>False</td>\n      <td>-100</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"features = [\"venue\", \"action\", \"trade\", \"price\", \"bid\", \"ask\", \"bid_size\", \"ask_size\", \"flux\"]\nnum_features = [\"price\", \"bid\", \"ask\", \"bid_size\", \"ask_size\", \"flux\"]\n\n# Pivot the dataset\npivoted = df.pivot(index=\"obs_id\", columns=\"operation_id\", values=features)\n\n# Flatten the MultiIndex columns\npivoted.columns = [f\"{feature}_op_{op_id}\" for feature, op_id in pivoted.columns]\npivoted.reset_index(inplace=True)\n\npivoted.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:54:10.088993Z","iopub.execute_input":"2024-11-24T00:54:10.089560Z","iopub.status.idle":"2024-11-24T00:54:21.825435Z","shell.execute_reply.started":"2024-11-24T00:54:10.089524Z","shell.execute_reply":"2024-11-24T00:54:21.824563Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   obs_id venue_op_0 venue_op_1 venue_op_2 venue_op_3 venue_op_4 venue_op_5  \\\n0       0          4          4          4          4          4          1   \n1       1          4          4          4          0          0          0   \n2       2          4          4          4          4          0          0   \n3       3          4          0          4          4          0          2   \n4       4          4          5          4          4          4          3   \n\n  venue_op_6 venue_op_7 venue_op_8  ... flux_op_90 flux_op_91 flux_op_92  \\\n0          4          4          4  ...       -100       -100       -100   \n1          4          4          4  ...        -79         -5        -47   \n2          0          0          0  ...       -100         64        -64   \n3          4          2          4  ...        100       -100        100   \n4          4          4          4  ...        100       -100       -100   \n\n  flux_op_93 flux_op_94 flux_op_95 flux_op_96 flux_op_97 flux_op_98 flux_op_99  \n0       -100       -100        100        100        100       -100        100  \n1       -100        -75         10         -4         10         10       -100  \n2        100        100       -100       -100       -100         10        100  \n3        100       -100         21         21         21       -200        200  \n4        100       -100        100       -400       -100         20        100  \n\n[5 rows x 901 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs_id</th>\n      <th>venue_op_0</th>\n      <th>venue_op_1</th>\n      <th>venue_op_2</th>\n      <th>venue_op_3</th>\n      <th>venue_op_4</th>\n      <th>venue_op_5</th>\n      <th>venue_op_6</th>\n      <th>venue_op_7</th>\n      <th>venue_op_8</th>\n      <th>...</th>\n      <th>flux_op_90</th>\n      <th>flux_op_91</th>\n      <th>flux_op_92</th>\n      <th>flux_op_93</th>\n      <th>flux_op_94</th>\n      <th>flux_op_95</th>\n      <th>flux_op_96</th>\n      <th>flux_op_97</th>\n      <th>flux_op_98</th>\n      <th>flux_op_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>-100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>-79</td>\n      <td>-5</td>\n      <td>-47</td>\n      <td>-100</td>\n      <td>-75</td>\n      <td>10</td>\n      <td>-4</td>\n      <td>10</td>\n      <td>10</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-100</td>\n      <td>64</td>\n      <td>-64</td>\n      <td>100</td>\n      <td>100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>10</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>100</td>\n      <td>-100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>-100</td>\n      <td>21</td>\n      <td>21</td>\n      <td>21</td>\n      <td>-200</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>100</td>\n      <td>-100</td>\n      <td>100</td>\n      <td>-400</td>\n      <td>-100</td>\n      <td>20</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 901 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"**On change le type des colonnes, en effet, après l'utilisation de la méthode pivot, on se trouve avec des types objets qui ne sont pas reconnus par XGBoost. Ainsi, il est indispensable de changer le type des colonnes.**","metadata":{}},{"cell_type":"code","source":"for i in range(100):\n    for col in num_features:\n        pivoted[col + f\"_op_{i}\"] = pivoted[col + f\"_op_{i}\"].astype(\"float64\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:54:21.826996Z","iopub.execute_input":"2024-11-24T00:54:21.827355Z","iopub.status.idle":"2024-11-24T00:54:42.426811Z","shell.execute_reply.started":"2024-11-24T00:54:21.827300Z","shell.execute_reply":"2024-11-24T00:54:42.425891Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"for col in pivoted.select_dtypes(include=[\"object\", \"string\"]).columns:\n    pivoted[col] = pivoted[col].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:54:42.427943Z","iopub.execute_input":"2024-11-24T00:54:42.428210Z","iopub.status.idle":"2024-11-24T00:54:51.663891Z","shell.execute_reply.started":"2024-11-24T00:54:42.428184Z","shell.execute_reply":"2024-11-24T00:54:51.663166Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"pivoted.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:54:51.665489Z","iopub.execute_input":"2024-11-24T00:54:51.665756Z","iopub.status.idle":"2024-11-24T00:54:51.675288Z","shell.execute_reply.started":"2024-11-24T00:54:51.665732Z","shell.execute_reply":"2024-11-24T00:54:51.674273Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"obs_id           int64\nvenue_op_0    category\nvenue_op_1    category\nvenue_op_2    category\nvenue_op_3    category\n                ...   \nflux_op_95     float64\nflux_op_96     float64\nflux_op_97     float64\nflux_op_98     float64\nflux_op_99     float64\nLength: 901, dtype: object"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"y = Y_train.drop(columns = [\"obs_id\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:54:51.676448Z","iopub.execute_input":"2024-11-24T00:54:51.676879Z","iopub.status.idle":"2024-11-24T00:54:51.685852Z","shell.execute_reply.started":"2024-11-24T00:54:51.676842Z","shell.execute_reply":"2024-11-24T00:54:51.684875Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\npivoted[\"target\"] = y.values\nsample_frac = 0.2  # Fraction of data to sample\n\n# Group by the 'target' column and sample the same fraction from each group\ndf_sample = pivoted.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=sample_frac, random_state=42))\n\npivoted = pivoted.drop(columns = [\"target\"])\n# Split\nxtrain, xtest, ytrain, ytest = train_test_split(df_sample.drop(columns = [\"target\"]), df_sample[\"target\"],\n                                                stratify= df_sample[\"target\"],test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:24:19.787420Z","iopub.execute_input":"2024-11-24T01:24:19.787795Z","iopub.status.idle":"2024-11-24T01:24:23.239209Z","shell.execute_reply.started":"2024-11-24T01:24:19.787764Z","shell.execute_reply":"2024-11-24T01:24:23.238117Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/4163633818.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sample = pivoted.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=sample_frac, random_state=42))\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\n\n\n\n# --- XGBoost Model ---\nxgb_model = xgb.XGBClassifier(n_estimators = 400,\n                              tree_method='hist',device = \"cuda\", random_state=42, enable_categorical = True)\n\n\n\nxgb_model.fit(xtrain, ytrain)\n\n\ny_pred_xgb = xgb_model.predict(xtest)\n\n# Evaluate the XGBoost model\nprint(\"XGBoost Accuracy:\", accuracy_score(ytest, y_pred_xgb))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:14:08.168475Z","iopub.execute_input":"2024-11-24T01:14:08.168848Z","iopub.status.idle":"2024-11-24T01:16:57.484451Z","shell.execute_reply.started":"2024-11-24T01:14:08.168817Z","shell.execute_reply":"2024-11-24T01:16:57.483474Z"}},"outputs":[{"name":"stdout","text":"XGBoost Accuracy: 0.2856032338308458\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df_test = X_test.copy()\ndf_test[\"operation_id\"] = df_test.groupby(\"obs_id\").cumcount()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:17:36.913107Z","iopub.execute_input":"2024-11-24T01:17:36.913464Z","iopub.status.idle":"2024-11-24T01:17:37.572215Z","shell.execute_reply.started":"2024-11-24T01:17:36.913432Z","shell.execute_reply":"2024-11-24T01:17:37.571506Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"pivoted_test = df_test.pivot(index=\"obs_id\", columns=\"operation_id\", values=features)\n\n# Flatten the MultiIndex columns\npivoted_test.columns = [f\"{feature}_op_{op_id}\" for feature, op_id in pivoted_test.columns]\npivoted_test.reset_index(inplace=True)\n\nfor i in range(100):\n    for col in num_features:\n        pivoted_test[col + f\"_op_{i}\"] = pivoted_test[col + f\"_op_{i}\"].astype(\"float64\")\n\nfor col in pivoted_test.select_dtypes(include=[\"object\", \"string\"]).columns:\n    pivoted_test[col] = pivoted_test[col].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:17:37.573800Z","iopub.execute_input":"2024-11-24T01:17:37.574498Z","iopub.status.idle":"2024-11-24T01:17:58.350675Z","shell.execute_reply.started":"2024-11-24T01:17:37.574455Z","shell.execute_reply":"2024-11-24T01:17:58.349841Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = xgb.XGBClassifier(n_estimators = 400,\n                              tree_method='hist',device = \"cuda\", enable_categorical = True)\nmodel.fit(pivoted, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:24:39.172080Z","iopub.execute_input":"2024-11-24T01:24:39.172831Z","iopub.status.idle":"2024-11-24T01:31:19.957563Z","shell.execute_reply.started":"2024-11-24T01:24:39.172798Z","shell.execute_reply":"2024-11-24T01:31:19.956556Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n              enable_categorical=True, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=400, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=True, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=400, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=True, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=400, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"Y_test = model.predict(pivoted_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:19.958954Z","iopub.execute_input":"2024-11-24T01:31:19.959227Z","iopub.status.idle":"2024-11-24T01:31:25.408344Z","shell.execute_reply.started":"2024-11-24T01:31:19.959199Z","shell.execute_reply":"2024-11-24T01:31:25.407627Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"dfY_test = pd.DataFrame({\"obs_id\" : [k for k in range(81600)], \"eqt_code_cat\": Y_test})\ndfY_test.to_csv(\"predictions2XGB.csv\", index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:31:35.668989Z","iopub.execute_input":"2024-11-24T01:31:35.669340Z","iopub.status.idle":"2024-11-24T01:31:35.754821Z","shell.execute_reply.started":"2024-11-24T01:31:35.669308Z","shell.execute_reply":"2024-11-24T01:31:35.754031Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## LSTM","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cfm-data/X_train_N1UvY30.csv\")\ny = pd.read_csv(\"/kaggle/input/cfm-data/y_train_or6m3Ta.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:33:26.870135Z","iopub.execute_input":"2024-11-24T01:33:26.871061Z","iopub.status.idle":"2024-11-24T01:33:51.095670Z","shell.execute_reply.started":"2024-11-24T01:33:26.871018Z","shell.execute_reply":"2024-11-24T01:33:51.094821Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\n\n# Encode categorical columns\ncategorical_cols = ['action', 'side', 'venue']\ndf_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n\n# Define features to keep\nfeature_cols = [col for col in df_encoded.columns if col not in ['obs_id', 'order_id', 'trade']]\n\n# Group features by `obs_id` into sequences\ngrouped = df_encoded.groupby('obs_id')\nX = np.stack([group[feature_cols].values for _, group in grouped])  # Shape: (num_obs_id, sequence_length, num_features)\n\n# Map `eqt_code_cat` labels to `obs_id`\nobs_to_label = y.set_index('obs_id')['eqt_code_cat']\n\n# Map labels to `obs_id` for grouped data\nlabels = np.array([obs_to_label.get(obs_id, np.nan) for obs_id in grouped.groups.keys()])\nlabels = labels[~np.isnan(labels)].astype(int)  # Remove NaNs and convert to integers\n\n# Ensure X and labels are aligned\nvalid_indices = ~np.isnan(labels)  # Ensure no missing labels\nX = X[valid_indices]\nlabels = labels[valid_indices]\n\n# Normalize \nscaler = StandardScaler()\nX_normalized = scaler.fit_transform(X.reshape(-1, X.shape[2])).reshape(X.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:33:56.753059Z","iopub.execute_input":"2024-11-24T01:33:56.753496Z","iopub.status.idle":"2024-11-24T01:36:05.374263Z","shell.execute_reply.started":"2024-11-24T01:33:56.753462Z","shell.execute_reply":"2024-11-24T01:36:05.373089Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\n\n# Detect TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)  \n    print(\"Running on TPU\")\nexcept ValueError:\n    strategy = tf.distribute.get_strategy()  \n    print(\"Running on CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:36:05.376054Z","iopub.execute_input":"2024-11-24T01:36:05.376357Z","iopub.status.idle":"2024-11-24T01:36:14.095304Z","shell.execute_reply.started":"2024-11-24T01:36:05.376330Z","shell.execute_reply":"2024-11-24T01:36:14.094094Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732412169.453920      13 service.cc:145] XLA service 0x5b404e77ffb0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1732412169.453993      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1732412169.453998      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1732412169.454001      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1732412169.454006      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1732412169.454010      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1732412169.454012      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1732412169.454015      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1732412169.454018      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nRunning on TPU\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional\n\n\nsequence_length = X_normalized.shape[1]\nnum_features = X_normalized.shape[2]\n\nwith strategy.scope():\n    model = Sequential([\n        Bidirectional(LSTM(128, return_sequences=True), input_shape=(sequence_length, num_features)),\n        Dropout(0.2),  # Regularization after the first Bidirectional LSTM\n        Bidirectional(LSTM(64)),\n        Dropout(0.2),  # Regularization after the second Bidirectional LSTM\n        Dense(16, activation='relu'),\n        Dense(len(np.unique(labels)), activation='softmax')  # For classification\n    ])\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    \n    model.fit(X_normalized, labels, epochs=34, batch_size=32)\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:36:14.096489Z","iopub.execute_input":"2024-11-24T01:36:14.096771Z","iopub.status.idle":"2024-11-24T02:17:37.394571Z","shell.execute_reply.started":"2024-11-24T01:36:14.096744Z","shell.execute_reply":"2024-11-24T02:17:37.393186Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1732412174.157385      13 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n/usr/local/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/34\n","output_type":"stream"},{"name":"stderr","text":"2024-11-24 01:36:23.920374: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.\nI0000 00:00:1732412184.175179     830 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(91bdfb30ddea1243:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   8/5025\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 15ms/step - accuracy: 0.0548 - loss: 3.1679    ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732412188.111802     830 tpu_compile_op_common.cc:245] Compilation of 91bdfb30ddea1243:0:0 with session name  took 3.936576809s and succeeded\nI0000 00:00:1732412188.136262     830 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(91bdfb30ddea1243:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_10664464056535047183\", property.function_library_fingerprint = 5660619254320728512, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732412188.136310     830 tpu_compilation_cache_interface.cc:541] After adding entry for key 91bdfb30ddea1243:0:0 with session_name  cache is 1 entries (21596825 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - accuracy: 0.1704 - loss: 2.6003\nEpoch 2/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.2792 - loss: 2.1656\nEpoch 3/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.4014 - loss: 1.8200\nEpoch 4/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.4643 - loss: 1.5992\nEpoch 5/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.5191 - loss: 1.4360\nEpoch 6/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.5575 - loss: 1.3101\nEpoch 7/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.5890 - loss: 1.2168\nEpoch 8/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.6101 - loss: 1.1426\nEpoch 9/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.6346 - loss: 1.0629\nEpoch 10/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.6521 - loss: 1.0242\nEpoch 11/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.6697 - loss: 0.9565\nEpoch 12/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.6837 - loss: 0.9144\nEpoch 13/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.6943 - loss: 0.8804\nEpoch 14/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.7142 - loss: 0.8231\nEpoch 15/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7156 - loss: 0.8205\nEpoch 16/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7369 - loss: 0.7729\nEpoch 17/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7428 - loss: 0.7353\nEpoch 18/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7513 - loss: 0.7234\nEpoch 19/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7537 - loss: 0.7042\nEpoch 20/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7644 - loss: 0.6918\nEpoch 21/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7666 - loss: 0.6719\nEpoch 22/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7749 - loss: 0.6503\nEpoch 23/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7751 - loss: 0.6395\nEpoch 24/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7853 - loss: 0.6144\nEpoch 25/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 15ms/step - accuracy: 0.7847 - loss: 0.6083\nEpoch 26/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7905 - loss: 0.5914\nEpoch 27/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.7973 - loss: 0.5814\nEpoch 28/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.5785\nEpoch 29/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.8004 - loss: 0.5623\nEpoch 30/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.8025 - loss: 0.5636\nEpoch 31/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.8074 - loss: 0.5464\nEpoch 32/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 14ms/step - accuracy: 0.8091 - loss: 0.5406\nEpoch 33/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.8113 - loss: 0.5376\nEpoch 34/34\n\u001b[1m5025/5025\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 14ms/step - accuracy: 0.8124 - loss: 0.5305\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"X_test = pd.read_csv(\"/kaggle/input/x-test/X_test_m4HAPAP.csv\")\n\nX_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\nX_test_grouped = X_test_encoded.groupby('obs_id')\nX_test_prepared = np.stack([group[feature_cols].values for _, group in X_test_grouped])\n\n# Normalize X_test \nX_test_normalized = scaler.transform(X_test_prepared.reshape(-1, X_test_prepared.shape[2])).reshape(X_test_prepared.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:18:12.350381Z","iopub.execute_input":"2024-11-24T02:18:12.350867Z","iopub.status.idle":"2024-11-24T02:19:20.754034Z","shell.execute_reply.started":"2024-11-24T02:18:12.350819Z","shell.execute_reply":"2024-11-24T02:19:20.752708Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"predictions = model.predict(X_test_normalized)\npredicted_classes = np.argmax(predictions, axis=1)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:19:20.762874Z","iopub.execute_input":"2024-11-24T02:19:20.763181Z","iopub.status.idle":"2024-11-24T02:19:40.332036Z","shell.execute_reply.started":"2024-11-24T02:19:20.763152Z","shell.execute_reply":"2024-11-24T02:19:40.330783Z"}},"outputs":[{"name":"stderr","text":"2024-11-24 02:19:22.929970: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node sequential_1/bidirectional_1/backward_lstm_1/lstm_cell_1/Cast/ReadVariableOp.\nI0000 00:00:1732414763.053887     817 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(8a77f1ca533e48c2:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  25/2550\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 7ms/step ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1732414763.441615     817 tpu_compile_op_common.cc:245] Compilation of 8a77f1ca533e48c2:0:0 with session name  took 387.679641ms and succeeded\nI0000 00:00:1732414763.444299     817 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(8a77f1ca533e48c2:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_532882549903817920\", property.function_library_fingerprint = 13478651180759773310, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1732414763.444328     817 tpu_compilation_cache_interface.cc:541] After adding entry for key 8a77f1ca533e48c2:0:0 with session_name  cache is 2 entries (23553475 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2550/2550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"obs_ids = list(X_test_grouped.groups.keys()) \noutput_df = pd.DataFrame({\n    'obs_id': obs_ids,\n    'eqt_code_cat': predicted_classes\n})\n\n# Save the DataFrame to a CSV file\noutput_df.to_csv('predicted_classesLSTM.csv', index=False)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:19:40.333863Z","iopub.execute_input":"2024-11-24T02:19:40.334185Z","iopub.status.idle":"2024-11-24T02:19:41.738157Z","shell.execute_reply.started":"2024-11-24T02:19:40.334154Z","shell.execute_reply":"2024-11-24T02:19:41.736948Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}